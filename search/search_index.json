{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pytest_cache_assert \u2693\ufe0e Cache assertion data to simplify regression testing of complex serializable data Installation \u2693\ufe0e poetry add pytest_assert_check --dev Quick Start \u2693\ufe0e The primary use case of this package is regression testing of large, serializable dictionaries, such as from an API under development. You may have parameterized test cases where you need to assert that the created dictionary stays the same, but you don\u2019t want to manually generate the expected fields and values to compare. Instead you can capture a snapshot of the serialized data and cache the result then use the cached data to check for consistency in repeated test runs. The cached files should be checked into version control, which can be very useful as documentation This package can minimize test case logic, while improving test thoroughness This project was heavily inspired by the excellent pytest-recording Alternatives \u2693\ufe0e pytest-recording : this is the package I use and highly recommend for recording and replaying external API communication so that API requests only need to be made once for unit testing (i.e. recording API responses from Github\u2019s API called from a test suite) pytest-snapshot : I only found this package after already releasing a 1.0.0 version of pytest_assert_cache . This package can be more configurable with a user-specified serializer and might be a good alternative. See their documentation for more info snapshottest : This was another find after releasing a 1.0.0 version and would probably be a good alterantive for most users pytest-snapshot is much more configurable, has many more users, and is a better name I really like the ability to quickly regenerate the cached files with \u2013snapshot-update There is some interesting discussion on how best to handle fields that change between tests dirty-equals : broadly check values (i.e. assert result == {'counter': IsPositiveInt, ...} , etc.) rather than accessing and checking each field individual, which makes test easier to write and output errors easier to review Basic Example \u2693\ufe0e You\u2019ve created a new project called package_a with one file package_a/source_file.py and test tests/test_file.py \"\"\"package_a/source_file.py\"\"\" import sys from datetime import datetime from typing import Any , Dict , List , Optional from beartype import beartype from pydantic import BaseModel class User ( BaseModel ): # noqa: H601 \"\"\"Example from pydantic documentation.\"\"\" id : int # noqa: A003,VNE003 name = 'John Doe' signup_ts : Optional [ datetime ] = None friends : List [ int ] = [] @beartype def create_data ( name : str ) -> Dict [ str , Any ]: \"\"\"Arbitrary function that returns a dictionary. This demonstration uses pydantic, but any dictionary can be tested! \"\"\" return User ( id = sys . maxsize , name = name ) . dict () \"\"\"tests/test_file.py\"\"\" import pytest from package_a.source_file import create_data @pytest . mark . parametrize ( 'name' , [ 'Test Name 1' , 'Test Name 2' ]) def test_create_data ( name , assert_against_cache ): \"\"\"Basic test of create_data().\"\"\" result = create_data ( name = name ) # One could manually create the expected dictionary cache = { 'id' : 9223372036854775807 , 'signup_ts' : None , 'friends' : [], 'name' : name } assert result == cache # ---------------------------------------------------------------------------------- # Or utilize the pytest_cache_assert fixture to compare against the last cached version assert_against_cache ( result ) pytest_cache_assert will automatically create: tests/cache-assert/source_file/test_file/test_create_data-[Test Name 1].json (and test_create_data[Test Name 2].json ) for each of the parameters when first run by caching the result . Below is the example for test_create_data-[Test Name 1].json { \"_info\" : [ { \"func_args\" : { \"name\" : \"Test Name 1\" }, \"test_file\" : \"test_readme.py\" , \"test_name\" : \"test_create_data\" } ], \"_json\" : { \"friends\" : [], \"id\" : 9223372036854775807 , \"name\" : \"Test Name 1\" , \"signup_ts\" : null } } The cached JSON files must be checked into version control and if needed, can be manually edited or deleted so that they will be regenerated when the test suite is next run More Examples \u2693\ufe0e In your cached dictionary, you may have variable values with more complex logic to verify, such as dates, UUIDs, etc. These can be selectively ignored, matched-if-null, or some other user-specified check: \"\"\"tests/test_main.py.\"\"\" from uuid import uuid4 from datetime import datetime , timedelta from pytest_cache_assert import KeyRule , check_suppress , check_type , Wildcards def test_assert_against_cache_key_rules ( assert_against_cache ): \"\"\"Demonstrate use of `key_rules`.\"\"\" now = datetime . now () cached_data = { 'date' : str ( now ), { 'nested' : { 'uuid' : str ( uuid4 ())}}, { 'ignored' : { 'a' : 1 , 'b' : 2 }}, } test_data = { 'date' : str ( now + timedelta ( hours = 3 )), { 'nested' : { 'uuid' : str ( uuid4 ())}}, { 'ignored' : { 'recursively' : { 'a' : { 'b' : { 'c' : 1 }}}}}, } key_rules = [ # Suppress keys 'ignored.a' and 'ignored.b' with the SINGLE wildcard, # which aren't present in the test-data and would otherwise error KeyRule ( pattern = [ 'ignored' , Wildcards . SINGLE ], func = check_suppress ), # The pattern can also recursively apply to data below KeyRule ( pattern = [ 'ignored' , 'recursively' , Wildcards . RECURSIVELY ], func = check_suppress , ), # Instead of suppressing, the type can be coerced from the string and verified # This is useful for datetime or UUID's where the string will be different, # but both values are the same type KeyRule ( pattern = [ 'date' ], func = check_type ), KeyRule ( pattern = [ 'nested' , 'uuid' ], func = check_type ), # Custom functions can also be specified to check a datetime format, etc. # The function must accept the keyword arguments 'old' and 'new' ] # In this example, the cache file has been deleted, so first call will recreate it assert_against_cache ( cached_data ) # Then this line demonstrates that key_rules will suppress the errors assert_against_cache ( test_data , key_rules = key_rules ) # While without key rules, an AssertionError is raised with pytest . raises ( AssertionError ): assert_against_cache ( test_data ) Or you may want to write your own custom checks against the serialized data, such as with Cerberus or another library. This is possible with the validator callable. The default validator is a no-op and that may be replaced with any custom function that raises an Exception on error. \"\"\"tests/test_main.py.\"\"\" import re import pytest from beartype import beartype from cerberus import Validator from cerberus.schema import SchemaError @beartype def cerberus_validator ( test_data ) -> None : \"\"\"Cerberus custom validator example.\"\"\" validator = Validator ({ 'result' : { 'type' : 'int' }}) assert validator . validate ( test_data ) def test_assert_against_cache_validator ( assert_against_cache ): \"\"\"Test the validator.\"\"\" expected = re . escape ( \"{'result': [{'type': ['Unsupported types: int']}]}\" ) with pytest . raises ( SchemaError , match = expected ): assert_against_cache ({ 'result' : False }, validator = cerberus_validator ) # act Even More Example \u2693\ufe0e For more examples, see Scripts or Tests Global Configuration Options \u2693\ufe0e See AssertConfig in plugin.py for configuration options and more information cache_dir_rel_path : set a custom relative path from the tests/ directory. Default is assert-cache/ extra_ser_rules : additional serialization rules that can be used generically on arbitrary data import pytest from pytest_cache_assert.plugin import AssertConfig @pytest . fixture ( scope = 'module' ) def cache_assert_config (): return AssertConfig ( cache_dir_rel_path = 'custom/cache/dir' ) Roadmap \u2693\ufe0e See the Open Issues and Milestones for current status and ./docs/CODE_TAG_SUMMARY.md for annotations in the source code. For release history, see the ./docs/CHANGELOG.md Planned Global Configuration Options \u2693\ufe0e These are ideas for future options that are not currently implemented, but could be if there is enough interest: PLANNED: Consider a record mode that will always-write to regenerate the cache while working on development The other edge case where a mode might be helpful is when file names or test names are changed and the cache metadata has too many duplicates and needs to be refreshed. Maybe a rewrite_metadata setting would be useful with options: Always , Once (Default), or Never Note that errors where the same test is appending to the metadata are problems with the code and should not necessarily need configuration. The only exception would be hypothesis testing where the inputs could be variable. In this case, a function argument to turn off metadata would be useful (rather than a global config) FIXME: Don\u2019t store variable datetime in the func_args! PLANNED: Provide CLI arguments like pytest-recording ( request.config.getoption(\"--record-mode\") or \"none\" ) for one-time changes to configuration PLANNED: Consider filters to prevent secrets from being cached: filter_headers=[['authorization', 'id'], ['authorization', 'cookies']] Other Planned Features \u2693\ufe0e PLANNED: Consider inline corrections to cached data like this feature from Jest Show the diff between the cached data and the test data? Would need to look for a package that can show the comparison between two dictionaries in terminal ydiff might be a great choice, but I would need to support git (and ask if anyone needs SVN support) to write the change and compare. Probably better to more directly ask if the user wants the test case (shown by name and maybe a brief list of changes) to be replaced or not PLANNED: Add tips from Jest on best practices \u2013 treat snapshots as code, etc. Contributing \u2693\ufe0e See the Developer Guide, Contribution Guidelines, etc ./docs/DEVELOPER_GUIDE.md ./docs/STYLE_GUIDE.md ./docs/CONTRIBUTING.md ./docs/CODE_OF_CONDUCT.md ./docs/SECURITY.md License \u2693\ufe0e LICENSE","title":"pytest_cache_assert"},{"location":"#pytest_cache_assert","text":"Cache assertion data to simplify regression testing of complex serializable data","title":"pytest_cache_assert"},{"location":"#installation","text":"poetry add pytest_assert_check --dev","title":"Installation"},{"location":"#quick-start","text":"The primary use case of this package is regression testing of large, serializable dictionaries, such as from an API under development. You may have parameterized test cases where you need to assert that the created dictionary stays the same, but you don\u2019t want to manually generate the expected fields and values to compare. Instead you can capture a snapshot of the serialized data and cache the result then use the cached data to check for consistency in repeated test runs. The cached files should be checked into version control, which can be very useful as documentation This package can minimize test case logic, while improving test thoroughness This project was heavily inspired by the excellent pytest-recording","title":"Quick Start"},{"location":"#alternatives","text":"pytest-recording : this is the package I use and highly recommend for recording and replaying external API communication so that API requests only need to be made once for unit testing (i.e. recording API responses from Github\u2019s API called from a test suite) pytest-snapshot : I only found this package after already releasing a 1.0.0 version of pytest_assert_cache . This package can be more configurable with a user-specified serializer and might be a good alternative. See their documentation for more info snapshottest : This was another find after releasing a 1.0.0 version and would probably be a good alterantive for most users pytest-snapshot is much more configurable, has many more users, and is a better name I really like the ability to quickly regenerate the cached files with \u2013snapshot-update There is some interesting discussion on how best to handle fields that change between tests dirty-equals : broadly check values (i.e. assert result == {'counter': IsPositiveInt, ...} , etc.) rather than accessing and checking each field individual, which makes test easier to write and output errors easier to review","title":"Alternatives"},{"location":"#basic-example","text":"You\u2019ve created a new project called package_a with one file package_a/source_file.py and test tests/test_file.py \"\"\"package_a/source_file.py\"\"\" import sys from datetime import datetime from typing import Any , Dict , List , Optional from beartype import beartype from pydantic import BaseModel class User ( BaseModel ): # noqa: H601 \"\"\"Example from pydantic documentation.\"\"\" id : int # noqa: A003,VNE003 name = 'John Doe' signup_ts : Optional [ datetime ] = None friends : List [ int ] = [] @beartype def create_data ( name : str ) -> Dict [ str , Any ]: \"\"\"Arbitrary function that returns a dictionary. This demonstration uses pydantic, but any dictionary can be tested! \"\"\" return User ( id = sys . maxsize , name = name ) . dict () \"\"\"tests/test_file.py\"\"\" import pytest from package_a.source_file import create_data @pytest . mark . parametrize ( 'name' , [ 'Test Name 1' , 'Test Name 2' ]) def test_create_data ( name , assert_against_cache ): \"\"\"Basic test of create_data().\"\"\" result = create_data ( name = name ) # One could manually create the expected dictionary cache = { 'id' : 9223372036854775807 , 'signup_ts' : None , 'friends' : [], 'name' : name } assert result == cache # ---------------------------------------------------------------------------------- # Or utilize the pytest_cache_assert fixture to compare against the last cached version assert_against_cache ( result ) pytest_cache_assert will automatically create: tests/cache-assert/source_file/test_file/test_create_data-[Test Name 1].json (and test_create_data[Test Name 2].json ) for each of the parameters when first run by caching the result . Below is the example for test_create_data-[Test Name 1].json { \"_info\" : [ { \"func_args\" : { \"name\" : \"Test Name 1\" }, \"test_file\" : \"test_readme.py\" , \"test_name\" : \"test_create_data\" } ], \"_json\" : { \"friends\" : [], \"id\" : 9223372036854775807 , \"name\" : \"Test Name 1\" , \"signup_ts\" : null } } The cached JSON files must be checked into version control and if needed, can be manually edited or deleted so that they will be regenerated when the test suite is next run","title":"Basic Example"},{"location":"#more-examples","text":"In your cached dictionary, you may have variable values with more complex logic to verify, such as dates, UUIDs, etc. These can be selectively ignored, matched-if-null, or some other user-specified check: \"\"\"tests/test_main.py.\"\"\" from uuid import uuid4 from datetime import datetime , timedelta from pytest_cache_assert import KeyRule , check_suppress , check_type , Wildcards def test_assert_against_cache_key_rules ( assert_against_cache ): \"\"\"Demonstrate use of `key_rules`.\"\"\" now = datetime . now () cached_data = { 'date' : str ( now ), { 'nested' : { 'uuid' : str ( uuid4 ())}}, { 'ignored' : { 'a' : 1 , 'b' : 2 }}, } test_data = { 'date' : str ( now + timedelta ( hours = 3 )), { 'nested' : { 'uuid' : str ( uuid4 ())}}, { 'ignored' : { 'recursively' : { 'a' : { 'b' : { 'c' : 1 }}}}}, } key_rules = [ # Suppress keys 'ignored.a' and 'ignored.b' with the SINGLE wildcard, # which aren't present in the test-data and would otherwise error KeyRule ( pattern = [ 'ignored' , Wildcards . SINGLE ], func = check_suppress ), # The pattern can also recursively apply to data below KeyRule ( pattern = [ 'ignored' , 'recursively' , Wildcards . RECURSIVELY ], func = check_suppress , ), # Instead of suppressing, the type can be coerced from the string and verified # This is useful for datetime or UUID's where the string will be different, # but both values are the same type KeyRule ( pattern = [ 'date' ], func = check_type ), KeyRule ( pattern = [ 'nested' , 'uuid' ], func = check_type ), # Custom functions can also be specified to check a datetime format, etc. # The function must accept the keyword arguments 'old' and 'new' ] # In this example, the cache file has been deleted, so first call will recreate it assert_against_cache ( cached_data ) # Then this line demonstrates that key_rules will suppress the errors assert_against_cache ( test_data , key_rules = key_rules ) # While without key rules, an AssertionError is raised with pytest . raises ( AssertionError ): assert_against_cache ( test_data ) Or you may want to write your own custom checks against the serialized data, such as with Cerberus or another library. This is possible with the validator callable. The default validator is a no-op and that may be replaced with any custom function that raises an Exception on error. \"\"\"tests/test_main.py.\"\"\" import re import pytest from beartype import beartype from cerberus import Validator from cerberus.schema import SchemaError @beartype def cerberus_validator ( test_data ) -> None : \"\"\"Cerberus custom validator example.\"\"\" validator = Validator ({ 'result' : { 'type' : 'int' }}) assert validator . validate ( test_data ) def test_assert_against_cache_validator ( assert_against_cache ): \"\"\"Test the validator.\"\"\" expected = re . escape ( \"{'result': [{'type': ['Unsupported types: int']}]}\" ) with pytest . raises ( SchemaError , match = expected ): assert_against_cache ({ 'result' : False }, validator = cerberus_validator ) # act","title":"More Examples"},{"location":"#even-more-example","text":"For more examples, see Scripts or Tests","title":"Even More Example"},{"location":"#global-configuration-options","text":"See AssertConfig in plugin.py for configuration options and more information cache_dir_rel_path : set a custom relative path from the tests/ directory. Default is assert-cache/ extra_ser_rules : additional serialization rules that can be used generically on arbitrary data import pytest from pytest_cache_assert.plugin import AssertConfig @pytest . fixture ( scope = 'module' ) def cache_assert_config (): return AssertConfig ( cache_dir_rel_path = 'custom/cache/dir' )","title":"Global Configuration Options"},{"location":"#roadmap","text":"See the Open Issues and Milestones for current status and ./docs/CODE_TAG_SUMMARY.md for annotations in the source code. For release history, see the ./docs/CHANGELOG.md","title":"Roadmap"},{"location":"#planned-global-configuration-options","text":"These are ideas for future options that are not currently implemented, but could be if there is enough interest: PLANNED: Consider a record mode that will always-write to regenerate the cache while working on development The other edge case where a mode might be helpful is when file names or test names are changed and the cache metadata has too many duplicates and needs to be refreshed. Maybe a rewrite_metadata setting would be useful with options: Always , Once (Default), or Never Note that errors where the same test is appending to the metadata are problems with the code and should not necessarily need configuration. The only exception would be hypothesis testing where the inputs could be variable. In this case, a function argument to turn off metadata would be useful (rather than a global config) FIXME: Don\u2019t store variable datetime in the func_args! PLANNED: Provide CLI arguments like pytest-recording ( request.config.getoption(\"--record-mode\") or \"none\" ) for one-time changes to configuration PLANNED: Consider filters to prevent secrets from being cached: filter_headers=[['authorization', 'id'], ['authorization', 'cookies']]","title":"Planned Global Configuration Options"},{"location":"#other-planned-features","text":"PLANNED: Consider inline corrections to cached data like this feature from Jest Show the diff between the cached data and the test data? Would need to look for a package that can show the comparison between two dictionaries in terminal ydiff might be a great choice, but I would need to support git (and ask if anyone needs SVN support) to write the change and compare. Probably better to more directly ask if the user wants the test case (shown by name and maybe a brief list of changes) to be replaced or not PLANNED: Add tips from Jest on best practices \u2013 treat snapshots as code, etc.","title":"Other Planned Features"},{"location":"#contributing","text":"See the Developer Guide, Contribution Guidelines, etc ./docs/DEVELOPER_GUIDE.md ./docs/STYLE_GUIDE.md ./docs/CONTRIBUTING.md ./docs/CODE_OF_CONDUCT.md ./docs/SECURITY.md","title":"Contributing"},{"location":"#license","text":"LICENSE","title":"License"},{"location":"adr/","text":"ADR Documentation \u2693\ufe0e ADR : Architectural Design Decision ADRs \u2693\ufe0e ADR 000: Meta-ADR.md","title":"ADR Documentation"},{"location":"adr/#adr-documentation","text":"ADR : Architectural Design Decision","title":"ADR Documentation"},{"location":"adr/#adrs","text":"ADR 000: Meta-ADR.md","title":"ADRs"},{"location":"adr/NNN-Template/","text":"[short title of solved problem and solution] \u2693\ufe0e Status: [proposed | rejected | accepted | deprecated | \u2026 | superseded by ADR-0005 ] Deciders: [list everyone involved in the decision] Date: [YYYY-MM-DD when the decision was last updated] Technical Story: [description | ticket/issue URL] Context and Problem Statement \u2693\ufe0e [Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.] Decision Drivers \u2693\ufe0e [driver 1, e.g., a force, facing concern, \u2026] [driver 2, e.g., a force, facing concern, \u2026] \u2026 Considered Options \u2693\ufe0e [option 1] [option 2] [option 3] \u2026 Decision Outcome \u2693\ufe0e Chosen option: \u201c[option 1]\u201c, because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | \u2026 | comes out best (see below)]. Positive Consequences \u2693\ufe0e [e.g., improvement of quality attribute satisfaction, follow-up decisions required, \u2026] \u2026 Negative Consequences \u2693\ufe0e [e.g., compromising quality attribute, follow-up decisions required, \u2026] \u2026 Pros and Cons of the Options \u2693\ufe0e [option 1] \u2693\ufe0e [example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026 [option 2] \u2693\ufe0e [example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026 [option 3] \u2693\ufe0e [example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026 Links \u2693\ufe0e [Link type] [Link to ADR] \u2026","title":"\\[short title of solved problem and solution\\]"},{"location":"adr/NNN-Template/#short-title-of-solved-problem-and-solution","text":"Status: [proposed | rejected | accepted | deprecated | \u2026 | superseded by ADR-0005 ] Deciders: [list everyone involved in the decision] Date: [YYYY-MM-DD when the decision was last updated] Technical Story: [description | ticket/issue URL]","title":"[short title of solved problem and solution]"},{"location":"adr/NNN-Template/#context-and-problem-statement","text":"[Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.]","title":"Context and Problem Statement"},{"location":"adr/NNN-Template/#decision-drivers","text":"[driver 1, e.g., a force, facing concern, \u2026] [driver 2, e.g., a force, facing concern, \u2026] \u2026","title":"Decision Drivers "},{"location":"adr/NNN-Template/#considered-options","text":"[option 1] [option 2] [option 3] \u2026","title":"Considered Options"},{"location":"adr/NNN-Template/#decision-outcome","text":"Chosen option: \u201c[option 1]\u201c, because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | \u2026 | comes out best (see below)].","title":"Decision Outcome"},{"location":"adr/NNN-Template/#positive-consequences","text":"[e.g., improvement of quality attribute satisfaction, follow-up decisions required, \u2026] \u2026","title":"Positive Consequences "},{"location":"adr/NNN-Template/#negative-consequences","text":"[e.g., compromising quality attribute, follow-up decisions required, \u2026] \u2026","title":"Negative Consequences "},{"location":"adr/NNN-Template/#pros-and-cons-of-the-options","text":"","title":"Pros and Cons of the Options "},{"location":"adr/NNN-Template/#option-1","text":"[example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026","title":"[option 1]"},{"location":"adr/NNN-Template/#option-2","text":"[example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026","title":"[option 2]"},{"location":"adr/NNN-Template/#option-3","text":"[example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026","title":"[option 3]"},{"location":"adr/NNN-Template/#links","text":"[Link type] [Link to ADR] \u2026","title":"Links "},{"location":"docs/CHANGELOG/","text":"Unreleased \u2693\ufe0e Feat \u2693\ufe0e improve configurability with AssertConfig introduce internally configurable punq 1.2.1 (2022-02-27) \u2693\ufe0e Fix \u2693\ufe0e support Paths 1.2.0 (2022-02-27) \u2693\ufe0e Fix \u2693\ufe0e implement serializer before diffing failing tests and run doit Feat \u2693\ufe0e WIP serializer to support functions copier update. Add Github Actions Refactor \u2693\ufe0e use next generation attrs syntax 1.1.1 (2022-02-18) \u2693\ufe0e Fix \u2693\ufe0e show the changelog on PyPi Refactor \u2693\ufe0e drop 2021 prefix on tags 1.1.0 (2022-02-18) \u2693\ufe0e Refactor \u2693\ufe0e use beartype\u2019s typing imports Feat \u2693\ufe0e new assert_against_dict for in-memory comparison add support for comparing date-times Fix \u2693\ufe0e argument order issues in main datetime comparison logic 1.0.0 (2021-11-02) \u2693\ufe0e Fix \u2693\ufe0e correctly implement an optional fixture make config fixture optional Feat \u2693\ufe0e improve serialization 1.0.0rc0 (2021-11-02) \u2693\ufe0e Refactor \u2693\ufe0e code cleanup & documentation updates simplify merge_metadata logic serialize the func_args metadata recursively improve code quality of _raw_diff Feat \u2693\ufe0e support comparison of lists always write metadata as a list customizable cache directory support lists of dictionaries replace asterisk string with Wildcard enum support UUID in check_type Fix \u2693\ufe0e support dictionary keys with dots add CNAME for custom subdomain add missing check_imports file 0.1.0 (2021-10-31) \u2693\ufe0e Fix \u2693\ufe0e add tests and verify correctness of KeyRule use full name instead of custom indexing for cache use 2-spaces on JSON for pre-commit reduce stored metadata and check args re-run \u201cpoetry install\u201d after entrypoint changes Feat \u2693\ufe0e implement key rules implement dictdiffer wrapper initialize decoupled differ and error message (WIP) use dictdiffer for quick fix for assertion messages resolve cache file name based on pytest metadata initial attempt at pytest plugin initialize package code and tests start with Readme (RDD) initialized project with copier Refactor \u2693\ufe0e rename checks to main rename check_assert to assert_against_cache & update README drop transformer and match_precision update notes and implementation plans","title":"CHANGELOG"},{"location":"docs/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"docs/CHANGELOG/#feat","text":"improve configurability with AssertConfig introduce internally configurable punq","title":"Feat"},{"location":"docs/CHANGELOG/#121-2022-02-27","text":"","title":"1.2.1 (2022-02-27)"},{"location":"docs/CHANGELOG/#fix","text":"support Paths","title":"Fix"},{"location":"docs/CHANGELOG/#120-2022-02-27","text":"","title":"1.2.0 (2022-02-27)"},{"location":"docs/CHANGELOG/#fix_1","text":"implement serializer before diffing failing tests and run doit","title":"Fix"},{"location":"docs/CHANGELOG/#feat_1","text":"WIP serializer to support functions copier update. Add Github Actions","title":"Feat"},{"location":"docs/CHANGELOG/#refactor","text":"use next generation attrs syntax","title":"Refactor"},{"location":"docs/CHANGELOG/#111-2022-02-18","text":"","title":"1.1.1 (2022-02-18)"},{"location":"docs/CHANGELOG/#fix_2","text":"show the changelog on PyPi","title":"Fix"},{"location":"docs/CHANGELOG/#refactor_1","text":"drop 2021 prefix on tags","title":"Refactor"},{"location":"docs/CHANGELOG/#110-2022-02-18","text":"","title":"1.1.0 (2022-02-18)"},{"location":"docs/CHANGELOG/#refactor_2","text":"use beartype\u2019s typing imports","title":"Refactor"},{"location":"docs/CHANGELOG/#feat_2","text":"new assert_against_dict for in-memory comparison add support for comparing date-times","title":"Feat"},{"location":"docs/CHANGELOG/#fix_3","text":"argument order issues in main datetime comparison logic","title":"Fix"},{"location":"docs/CHANGELOG/#100-2021-11-02","text":"","title":"1.0.0 (2021-11-02)"},{"location":"docs/CHANGELOG/#fix_4","text":"correctly implement an optional fixture make config fixture optional","title":"Fix"},{"location":"docs/CHANGELOG/#feat_3","text":"improve serialization","title":"Feat"},{"location":"docs/CHANGELOG/#100rc0-2021-11-02","text":"","title":"1.0.0rc0 (2021-11-02)"},{"location":"docs/CHANGELOG/#refactor_3","text":"code cleanup & documentation updates simplify merge_metadata logic serialize the func_args metadata recursively improve code quality of _raw_diff","title":"Refactor"},{"location":"docs/CHANGELOG/#feat_4","text":"support comparison of lists always write metadata as a list customizable cache directory support lists of dictionaries replace asterisk string with Wildcard enum support UUID in check_type","title":"Feat"},{"location":"docs/CHANGELOG/#fix_5","text":"support dictionary keys with dots add CNAME for custom subdomain add missing check_imports file","title":"Fix"},{"location":"docs/CHANGELOG/#010-2021-10-31","text":"","title":"0.1.0 (2021-10-31)"},{"location":"docs/CHANGELOG/#fix_6","text":"add tests and verify correctness of KeyRule use full name instead of custom indexing for cache use 2-spaces on JSON for pre-commit reduce stored metadata and check args re-run \u201cpoetry install\u201d after entrypoint changes","title":"Fix"},{"location":"docs/CHANGELOG/#feat_5","text":"implement key rules implement dictdiffer wrapper initialize decoupled differ and error message (WIP) use dictdiffer for quick fix for assertion messages resolve cache file name based on pytest metadata initial attempt at pytest plugin initialize package code and tests start with Readme (RDD) initialized project with copier","title":"Feat"},{"location":"docs/CHANGELOG/#refactor_4","text":"rename checks to main rename check_assert to assert_against_cache & update README drop transformer and match_precision update notes and implementation plans","title":"Refactor"},{"location":"docs/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct \u2693\ufe0e Our Pledge \u2693\ufe0e We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards \u2693\ufe0e Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others\u2019 private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities \u2693\ufe0e Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope \u2693\ufe0e This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement \u2693\ufe0e Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at dev.act.kyle@gmail.com. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines \u2693\ufe0e Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction \u2693\ufe0e Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning \u2693\ufe0e Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban \u2693\ufe0e Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban \u2693\ufe0e Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution \u2693\ufe0e This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla\u2019s code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.","title":"Contributor Covenant Code of Conduct"},{"location":"docs/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"docs/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"docs/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others\u2019 private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"docs/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"docs/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"docs/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at dev.act.kyle@gmail.com. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"docs/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"docs/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"docs/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"docs/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"docs/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"docs/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla\u2019s code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.","title":"Attribution"},{"location":"docs/CODE_TAG_SUMMARY/","text":"Task Summary \u2693\ufe0e Auto-Generated by pytest_cache_assert Type Comment Last Edit Source File PLANNED Consider a record mode that will always-write to regenerate the cache while working on development 2021-11-02 docs/README.md:222 FIXME Don\u2019t store variable datetime in the func_args! 2022-02-27 docs/README.md:225 PLANNED Provide CLI arguments like pytest-recording ( request.config.getoption(\"--record-mode\") or \"none\" ) for one-time changes to configuration 2021-11-02 docs/README.md:226 PLANNED Consider filters to prevent secrets from being cached: filter_headers=[['authorization', 'id'], ['authorization', 'cookies']] 2021-11-02 docs/README.md:227 PLANNED Consider inline corrections to cached data like this feature from Jest 2021-11-03 docs/README.md:231 PLANNED Add tips from Jest on best practices \u2013 treat snapshots as code, etc. 2021-11-03 docs/README.md:234 PLANNED Consider something like: Union[_NESTED_DICT, _NESTED_LIST] 2021-10-29 pytest_cache_assert/_check_assert/constants.py:50 FIXME Add example of what this is changing. I can\u2019t remember why this was necessary 2022-02-27 pytest_cache_assert/_check_assert/differ.py:115 FIXME Replace with programmatic imports? Maybe explicit imports to check backward compatibility of public API? 2022-02-18 scripts/check_imports.py:7 FIXME Create a new plugin fixture that can store and access strings as keys in a dictionary 2021-11-03 tests/test_main.py:23 TODO Support additional types: st.binary() 2022-02-27 tests/test_main.py:175 Found code tags for FIXME (4), TODO (1), PLANNED (6)","title":"Task Summary"},{"location":"docs/CODE_TAG_SUMMARY/#task-summary","text":"Auto-Generated by pytest_cache_assert Type Comment Last Edit Source File PLANNED Consider a record mode that will always-write to regenerate the cache while working on development 2021-11-02 docs/README.md:222 FIXME Don\u2019t store variable datetime in the func_args! 2022-02-27 docs/README.md:225 PLANNED Provide CLI arguments like pytest-recording ( request.config.getoption(\"--record-mode\") or \"none\" ) for one-time changes to configuration 2021-11-02 docs/README.md:226 PLANNED Consider filters to prevent secrets from being cached: filter_headers=[['authorization', 'id'], ['authorization', 'cookies']] 2021-11-02 docs/README.md:227 PLANNED Consider inline corrections to cached data like this feature from Jest 2021-11-03 docs/README.md:231 PLANNED Add tips from Jest on best practices \u2013 treat snapshots as code, etc. 2021-11-03 docs/README.md:234 PLANNED Consider something like: Union[_NESTED_DICT, _NESTED_LIST] 2021-10-29 pytest_cache_assert/_check_assert/constants.py:50 FIXME Add example of what this is changing. I can\u2019t remember why this was necessary 2022-02-27 pytest_cache_assert/_check_assert/differ.py:115 FIXME Replace with programmatic imports? Maybe explicit imports to check backward compatibility of public API? 2022-02-18 scripts/check_imports.py:7 FIXME Create a new plugin fixture that can store and access strings as keys in a dictionary 2021-11-03 tests/test_main.py:23 TODO Support additional types: st.binary() 2022-02-27 tests/test_main.py:175 Found code tags for FIXME (4), TODO (1), PLANNED (6)","title":"Task Summary"},{"location":"docs/CONTRIBUTING/","text":"Contributing \u2693\ufe0e Thanks for taking a look! This is primarily a personal project, but Pull Requests and Issues (questions, feature requests, etc.) are welcome. If you would like to submit a Pull Request, please open an issue first to discuss what you would like to change Pull Requests (PR) \u2693\ufe0e Code Development \u2693\ufe0e See ./DEVELOPER_GUIDE.md PR Process \u2693\ufe0e Fork the Project and Clone Create a new branch ( git checkout -b feat/feature-name ) Edit code; update documentation and tests; commit and push Before submitting the review and pushing, make sure to run poetry run doit Open a new Pull Request See the style guide for commit message format ( ./STYLE_GUIDE ) If you run into any issues, please check to see if there is an open issues or open a new one Other PR Tips \u2693\ufe0e Link the issue with Fixes #N in the Pull Request body Please add a short summary of why the change was made, what changed , and any relevant information or screenshots # SHA is the SHA of the commit you want to fix git commit --fixup = SHA # Once all the changes are approved, you can squash your commits: git rebase --interactive --autosquash main # Force Push git push --force","title":"Contributing"},{"location":"docs/CONTRIBUTING/#contributing","text":"Thanks for taking a look! This is primarily a personal project, but Pull Requests and Issues (questions, feature requests, etc.) are welcome. If you would like to submit a Pull Request, please open an issue first to discuss what you would like to change","title":"Contributing"},{"location":"docs/CONTRIBUTING/#pull-requests-pr","text":"","title":"Pull Requests (PR)"},{"location":"docs/CONTRIBUTING/#code-development","text":"See ./DEVELOPER_GUIDE.md","title":"Code Development"},{"location":"docs/CONTRIBUTING/#pr-process","text":"Fork the Project and Clone Create a new branch ( git checkout -b feat/feature-name ) Edit code; update documentation and tests; commit and push Before submitting the review and pushing, make sure to run poetry run doit Open a new Pull Request See the style guide for commit message format ( ./STYLE_GUIDE ) If you run into any issues, please check to see if there is an open issues or open a new one","title":"PR Process"},{"location":"docs/CONTRIBUTING/#other-pr-tips","text":"Link the issue with Fixes #N in the Pull Request body Please add a short summary of why the change was made, what changed , and any relevant information or screenshots # SHA is the SHA of the commit you want to fix git commit --fixup = SHA # Once all the changes are approved, you can squash your commits: git rebase --interactive --autosquash main # Force Push git push --force","title":"Other PR Tips"},{"location":"docs/DEVELOPER_GUIDE/","text":"Developer Notes \u2693\ufe0e Local Development \u2693\ufe0e git clone https://github.com/kyleking/pytest_cache_assert.git cd pytest_cache_assert poetry install # See the available tasks poetry run doit list # Run the default task list (lint, auto-format, test coverage, etc.) poetry run doit --continue # Make code changes and run specific tasks as needed: poetry run doit run test Publishing \u2693\ufe0e For testing, create an account on TestPyPi . Replace ... with the API token generated on TestPyPi|PyPi respectively poetry config repositories.testpypi https://test.pypi.org/legacy/ poetry config pypi-token.testpypi ... poetry run doit run publish_test_pypi # If you didn't configure a token, you will need to provide your username and password to publish To publish to the real PyPi poetry config pypi-token.pypi ... poetry run doit run publish # For a full release, triple check the default tasks, increment the version, rebuild documentation (twice), and publish! poetry run doit run --continue poetry run doit run cl_bump lock document deploy_docs publish # For pre-releases use cl_bump_pre poetry run doit run cl_bump_pre -p rc poetry run doit run lock document deploy_docs publish Current Status \u2693\ufe0e File Statements Missing Excluded Coverage pytest_cache_assert/__init__.py 4 0 0 100.0% pytest_cache_assert/_check_assert/__init__.py 0 0 0 100.0% pytest_cache_assert/_check_assert/caching.py 31 0 0 100.0% pytest_cache_assert/_check_assert/config.py 6 0 0 100.0% pytest_cache_assert/_check_assert/constants.py 22 1 0 95.5% pytest_cache_assert/_check_assert/differ.py 114 10 0 91.2% pytest_cache_assert/_check_assert/error_message.py 10 0 0 100.0% pytest_cache_assert/_check_assert/key_rules.py 61 3 0 95.1% pytest_cache_assert/_check_assert/serializer.py 32 2 0 93.8% pytest_cache_assert/main.py 41 7 0 82.9% pytest_cache_assert/plugin.py 44 2 0 95.5% Totals 365 25 0 93.2% Generated on: 2022-02-27T18:48:11.548256","title":"Developer Notes"},{"location":"docs/DEVELOPER_GUIDE/#developer-notes","text":"","title":"Developer Notes"},{"location":"docs/DEVELOPER_GUIDE/#local-development","text":"git clone https://github.com/kyleking/pytest_cache_assert.git cd pytest_cache_assert poetry install # See the available tasks poetry run doit list # Run the default task list (lint, auto-format, test coverage, etc.) poetry run doit --continue # Make code changes and run specific tasks as needed: poetry run doit run test","title":"Local Development"},{"location":"docs/DEVELOPER_GUIDE/#publishing","text":"For testing, create an account on TestPyPi . Replace ... with the API token generated on TestPyPi|PyPi respectively poetry config repositories.testpypi https://test.pypi.org/legacy/ poetry config pypi-token.testpypi ... poetry run doit run publish_test_pypi # If you didn't configure a token, you will need to provide your username and password to publish To publish to the real PyPi poetry config pypi-token.pypi ... poetry run doit run publish # For a full release, triple check the default tasks, increment the version, rebuild documentation (twice), and publish! poetry run doit run --continue poetry run doit run cl_bump lock document deploy_docs publish # For pre-releases use cl_bump_pre poetry run doit run cl_bump_pre -p rc poetry run doit run lock document deploy_docs publish","title":"Publishing"},{"location":"docs/DEVELOPER_GUIDE/#current-status","text":"File Statements Missing Excluded Coverage pytest_cache_assert/__init__.py 4 0 0 100.0% pytest_cache_assert/_check_assert/__init__.py 0 0 0 100.0% pytest_cache_assert/_check_assert/caching.py 31 0 0 100.0% pytest_cache_assert/_check_assert/config.py 6 0 0 100.0% pytest_cache_assert/_check_assert/constants.py 22 1 0 95.5% pytest_cache_assert/_check_assert/differ.py 114 10 0 91.2% pytest_cache_assert/_check_assert/error_message.py 10 0 0 100.0% pytest_cache_assert/_check_assert/key_rules.py 61 3 0 95.1% pytest_cache_assert/_check_assert/serializer.py 32 2 0 93.8% pytest_cache_assert/main.py 41 7 0 82.9% pytest_cache_assert/plugin.py 44 2 0 95.5% Totals 365 25 0 93.2% Generated on: 2022-02-27T18:48:11.548256","title":"Current Status"},{"location":"docs/SECURITY/","text":"Security \u2693\ufe0e Reporting Security Issues \u2693\ufe0e Do not open issues that might have security implications! It is critical that security related issues are reported privately so we have time to address them before they become public knowledge. Vulnerabilities can be reported by emailing core members: Kyle King ( dev.act.kyle@gmail.com ) Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Environment (e.g. Linux / Windows / macOS) Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages \u2693\ufe0e We prefer all communications to be in English. Attribution \u2693\ufe0e This file was based on the template from TezRomacH/python-package-template/SECURITY.md","title":"Security"},{"location":"docs/SECURITY/#security","text":"","title":"Security"},{"location":"docs/SECURITY/#reporting-security-issues","text":"Do not open issues that might have security implications! It is critical that security related issues are reported privately so we have time to address them before they become public knowledge. Vulnerabilities can be reported by emailing core members: Kyle King ( dev.act.kyle@gmail.com ) Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Environment (e.g. Linux / Windows / macOS) Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting Security Issues"},{"location":"docs/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"docs/SECURITY/#attribution","text":"This file was based on the template from TezRomacH/python-package-template/SECURITY.md","title":"Attribution"},{"location":"docs/STYLE_GUIDE/","text":"Personal Style Guides \u2693\ufe0e Git \u2693\ufe0e Use Conventional Commits and Commitizen The Changelog is an important part of a project (built with commitizen ). Use semver Conventional Commits \u2693\ufe0e type(scope): description / body The type feat MUST be used when a commit adds a new feature to your application or library. The type fix MUST be used when a commit represents a bug fix for your application. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., fix(parser): or issue number fix(#32): A ! can be used to indicate a breaking change, e.g. refactor!: drop support for Node 6 What if a commit fits multiple types? Go back and make multiple commits whenever possible. Part of the benefit of Conventional Commits is its ability to drive us to make more organized commits and PRs. It discourages moving fast in a disorganized way. It helps you be able to move fast long term across multiple projects with varied contributors. semver : fix : PATCH / feat : MINOR / BREAKING CHANGE : MAJOR Use git rebase -i to fix commit names prior to merging if incorrect types/scopes are used Commitizen Types and Scopes \u2693\ufe0e Types fix: A bug fix feat: A new feature docs: Documentation-only changes (code comments, separate docs) style: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons) perf: A code change that improves performance refactor: A change to production code that is not fix, feat, or perf test: Adding missing or correcting existing tests build: Changes that affect the build system or external dependencies (example scopes: pip, docker, npm) ci: Changes to our CI configuration files and scripts (example scopes: GitLabCI) Scopes Class, File name, Issue Number, other approved noun Git Message Guidelines \u2693\ufe0e Commit message guidelines Full sentence with verb ( lowercase ) and concise description. Below are modified examples for Conventional Commits fix(roles): bug in admin role permissions feat(ui): implement new button design build(pip): upgrade package to remove vulnerabilities refactor: file structure to improve code readability perf(cli): rewrite methods feat(api): endpoints to implement new customer dashboard How to write a good commit message A diff will tell you what changed, but only the commit message can properly tell you why. Keep in mind: This has all been said before . The seven rules of a great Git commit message Try for 50 characters, but consider 72 the hard limit Use the body to explain what and why vs. how Issue Labels and Milestones \u2693\ufe0e Personal Guide Labels Needs Discussion : ( #ff5722 ) Ticket needs discussion and prioritization Type: Bug : ( #d73a4a ) Something isn\u2019t working Type: Documentation : ( #69cde9 ) Documentation changes Type: Maintenance : ( #c5def5 ) Chore including build/dep, CI, refactor, or perf Type: Idea : ( #fbca04 ) General idea or concept that could become a feature request Type: Feature : ( #0075ca ) Clearly defined new feature request Milestones Current Tasks (Main Milestone) - name could change based on a specific project, sprint, or month Next Tasks Blue Sky Search is:open is:issue assignee:{{ author_username }} archived:false milestone:\"blue sky\" or no:milestone etc. Research [Sane Github Labels](https://medium.com/@dave_lunny/sane-github-labels-c5d2e6004b63) and see [sensible-github-labels](https://github.com/Relequestual/sensible-github-labels) for full descriptions of each \u201cit is much more helpful to see the status and type of all issues at a glance.\u201d One of each: Status: \u2026 Abandoned, Accepted, Available, Blocked, Completed, In Progress, On Hold, Pending, Review Needed, Revision Needed Type: \u2026 Bug, Maintenance, Question, Enhancement Priority: \u2026 Critical, High, Medium, Low [Britecharts](https://britecharts.github.io/britecharts/github-labels.html) Status: \u2026 On Review \u2013 Request that we are pondering if including or not Needs Reproducing \u2013 For bugs that need to be reproduced in order to get fixed Needs Design \u2013 Feature that needs a design Ready to Go \u2013 Issue that has been defined and is ready to get started with In Progress \u2013 Issue that is being worked on right now. Completed \u2013 Finished feature or fix Type: \u2026 Bug \u2013 An unexpected problem or unintended behavior Feature \u2013 A new feature request Maintenance \u2013 A regular maintenance chore or task, including refactors, build system, CI, performance improvements Documentation \u2013 A documentation improvement task Question \u2013 An issue or PR that needs more information or a user question Not Included Priority: They would add complexity and overhead due to the discussions, but could help with the roadmap Technology Labels: It can create too much overhead, as properly tag with technologies all the issues could be time consuming [Ian Bicking Blog](https://www.ianbicking.org/blog/2014/03/use-github-issues-to-organize-a-project.html) Milestone Overview What are we doing right now? What aren\u2019t we doing right now? 2a. Stuff we\u2019ll probably do soon 2b. Stuff we probably won\u2019t do soon What aren\u2019t we sure about? Milestone Descriptions Stuff we are doing right now: this is the \u201cmain\u201d milestone. We give it a name (like Alpha 2 or Strawberry Rhubarb Pie) and we write down what we are trying to accomplish with the milestone. We create a new milestone when we are ready for the next iteration. Stuff we\u2019ll probably do soon: this is a standing \u201c**Next Tasks**\u201d milestone. We never change or rename this milestone. We use a permanent \u201cNext Tasks\u201d milestone (as opposed to renaming it to \u201cAlpha 3\u201d or actual-next-iteration milestone) because we don\u2019t want to presume or default to including something in the real next iteration. When we\u2019re ready to start planning the next iteration we\u2019ll create a new milestone, and only deliberately move things into that milestone. Stuff we probably won\u2019t do soon: this is a standing \u201c**Blue Sky**\u201d milestone. We refer to these tickets and sometimes look through them, but they are easy to ignore, somewhat intentionally ignored. What aren\u2019t we sure about?: issues with no milestone. Label: \u201cNeeds Discussion\u201d - (addressed in a triage meeting) - use liberally for either big or small tickets \u201cIt\u2019s better to give people more power: it\u2019s actually helpful if people can overreach because it is an opportunity to establish where the limits really are and what purpose those limits have\u201d External Links \u2693\ufe0e TODO: Revisit Git: The Simple Guide Commit Messages and why use the present tense Github\u2019s Advice on Github Most Comprehensive Guide Git Pro Book (free) Bash Tab-Completion Snippet Python \u2693\ufe0e TODO: Revisit Python Style Guides https://gist.github.com/sloria/7001839 http://www.nilunder.com/blog/2013/08/03/pythonic-sensibilities/ https://innoq.github.io/cards42org_en/ https://docs.openstack.org/hacking/latest/user/hacking.html#styleguide https://www.python.org/doc/humor/ https://docs.python-guide.org/writing/reading/ https://realpython.com/python-refactoring/ ADRs \u2693\ufe0e TODO: Revisit Examples https://github.com/pawamoy/mkdocstrings/issues/28","title":"Personal Style Guides"},{"location":"docs/STYLE_GUIDE/#personal-style-guides","text":"","title":"Personal Style Guides"},{"location":"docs/STYLE_GUIDE/#git","text":"Use Conventional Commits and Commitizen The Changelog is an important part of a project (built with commitizen ). Use semver","title":"Git"},{"location":"docs/STYLE_GUIDE/#conventional-commits","text":"type(scope): description / body The type feat MUST be used when a commit adds a new feature to your application or library. The type fix MUST be used when a commit represents a bug fix for your application. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., fix(parser): or issue number fix(#32): A ! can be used to indicate a breaking change, e.g. refactor!: drop support for Node 6 What if a commit fits multiple types? Go back and make multiple commits whenever possible. Part of the benefit of Conventional Commits is its ability to drive us to make more organized commits and PRs. It discourages moving fast in a disorganized way. It helps you be able to move fast long term across multiple projects with varied contributors. semver : fix : PATCH / feat : MINOR / BREAKING CHANGE : MAJOR Use git rebase -i to fix commit names prior to merging if incorrect types/scopes are used","title":"Conventional Commits"},{"location":"docs/STYLE_GUIDE/#commitizen-types-and-scopes","text":"Types fix: A bug fix feat: A new feature docs: Documentation-only changes (code comments, separate docs) style: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons) perf: A code change that improves performance refactor: A change to production code that is not fix, feat, or perf test: Adding missing or correcting existing tests build: Changes that affect the build system or external dependencies (example scopes: pip, docker, npm) ci: Changes to our CI configuration files and scripts (example scopes: GitLabCI) Scopes Class, File name, Issue Number, other approved noun","title":"Commitizen Types and Scopes"},{"location":"docs/STYLE_GUIDE/#git-message-guidelines","text":"Commit message guidelines Full sentence with verb ( lowercase ) and concise description. Below are modified examples for Conventional Commits fix(roles): bug in admin role permissions feat(ui): implement new button design build(pip): upgrade package to remove vulnerabilities refactor: file structure to improve code readability perf(cli): rewrite methods feat(api): endpoints to implement new customer dashboard How to write a good commit message A diff will tell you what changed, but only the commit message can properly tell you why. Keep in mind: This has all been said before . The seven rules of a great Git commit message Try for 50 characters, but consider 72 the hard limit Use the body to explain what and why vs. how","title":"Git Message Guidelines"},{"location":"docs/STYLE_GUIDE/#issue-labels-and-milestones","text":"Personal Guide Labels Needs Discussion : ( #ff5722 ) Ticket needs discussion and prioritization Type: Bug : ( #d73a4a ) Something isn\u2019t working Type: Documentation : ( #69cde9 ) Documentation changes Type: Maintenance : ( #c5def5 ) Chore including build/dep, CI, refactor, or perf Type: Idea : ( #fbca04 ) General idea or concept that could become a feature request Type: Feature : ( #0075ca ) Clearly defined new feature request Milestones Current Tasks (Main Milestone) - name could change based on a specific project, sprint, or month Next Tasks Blue Sky Search is:open is:issue assignee:{{ author_username }} archived:false milestone:\"blue sky\" or no:milestone etc. Research [Sane Github Labels](https://medium.com/@dave_lunny/sane-github-labels-c5d2e6004b63) and see [sensible-github-labels](https://github.com/Relequestual/sensible-github-labels) for full descriptions of each \u201cit is much more helpful to see the status and type of all issues at a glance.\u201d One of each: Status: \u2026 Abandoned, Accepted, Available, Blocked, Completed, In Progress, On Hold, Pending, Review Needed, Revision Needed Type: \u2026 Bug, Maintenance, Question, Enhancement Priority: \u2026 Critical, High, Medium, Low [Britecharts](https://britecharts.github.io/britecharts/github-labels.html) Status: \u2026 On Review \u2013 Request that we are pondering if including or not Needs Reproducing \u2013 For bugs that need to be reproduced in order to get fixed Needs Design \u2013 Feature that needs a design Ready to Go \u2013 Issue that has been defined and is ready to get started with In Progress \u2013 Issue that is being worked on right now. Completed \u2013 Finished feature or fix Type: \u2026 Bug \u2013 An unexpected problem or unintended behavior Feature \u2013 A new feature request Maintenance \u2013 A regular maintenance chore or task, including refactors, build system, CI, performance improvements Documentation \u2013 A documentation improvement task Question \u2013 An issue or PR that needs more information or a user question Not Included Priority: They would add complexity and overhead due to the discussions, but could help with the roadmap Technology Labels: It can create too much overhead, as properly tag with technologies all the issues could be time consuming [Ian Bicking Blog](https://www.ianbicking.org/blog/2014/03/use-github-issues-to-organize-a-project.html) Milestone Overview What are we doing right now? What aren\u2019t we doing right now? 2a. Stuff we\u2019ll probably do soon 2b. Stuff we probably won\u2019t do soon What aren\u2019t we sure about? Milestone Descriptions Stuff we are doing right now: this is the \u201cmain\u201d milestone. We give it a name (like Alpha 2 or Strawberry Rhubarb Pie) and we write down what we are trying to accomplish with the milestone. We create a new milestone when we are ready for the next iteration. Stuff we\u2019ll probably do soon: this is a standing \u201c**Next Tasks**\u201d milestone. We never change or rename this milestone. We use a permanent \u201cNext Tasks\u201d milestone (as opposed to renaming it to \u201cAlpha 3\u201d or actual-next-iteration milestone) because we don\u2019t want to presume or default to including something in the real next iteration. When we\u2019re ready to start planning the next iteration we\u2019ll create a new milestone, and only deliberately move things into that milestone. Stuff we probably won\u2019t do soon: this is a standing \u201c**Blue Sky**\u201d milestone. We refer to these tickets and sometimes look through them, but they are easy to ignore, somewhat intentionally ignored. What aren\u2019t we sure about?: issues with no milestone. Label: \u201cNeeds Discussion\u201d - (addressed in a triage meeting) - use liberally for either big or small tickets \u201cIt\u2019s better to give people more power: it\u2019s actually helpful if people can overreach because it is an opportunity to establish where the limits really are and what purpose those limits have\u201d","title":"Issue Labels and Milestones"},{"location":"docs/STYLE_GUIDE/#external-links","text":"TODO: Revisit Git: The Simple Guide Commit Messages and why use the present tense Github\u2019s Advice on Github Most Comprehensive Guide Git Pro Book (free) Bash Tab-Completion Snippet","title":"External Links"},{"location":"docs/STYLE_GUIDE/#python","text":"TODO: Revisit Python Style Guides https://gist.github.com/sloria/7001839 http://www.nilunder.com/blog/2013/08/03/pythonic-sensibilities/ https://innoq.github.io/cards42org_en/ https://docs.openstack.org/hacking/latest/user/hacking.html#styleguide https://www.python.org/doc/humor/ https://docs.python-guide.org/writing/reading/ https://realpython.com/python-refactoring/","title":"Python"},{"location":"docs/STYLE_GUIDE/#adrs","text":"TODO: Revisit Examples https://github.com/pawamoy/mkdocstrings/issues/28","title":"ADRs"},{"location":"modules/pytest_cache_assert/","text":"pytest_cache_assert \u2693\ufe0e pytest_cache_assert. View Source \"\"\"pytest_cache_assert.\"\"\" from ._check_assert.constants import Wildcards # noqa: F401 from ._check_assert.key_rules import ( # noqa: F401 Comparator , KeyRule , check_exact , check_suppress , check_type , gen_check_date_proximity , gen_check_date_range , ) __version__ = '1.3.0' __pkg_name__ = 'pytest_cache_assert' # ====== Above is the recommended code from calcipy_template and may be updated on new releases ====== Sub-modules \u2693\ufe0e pytest_cache_assert.main pytest_cache_assert.plugin","title":"pytest_cache_assert"},{"location":"modules/pytest_cache_assert/#pytest_cache_assert","text":"pytest_cache_assert. View Source \"\"\"pytest_cache_assert.\"\"\" from ._check_assert.constants import Wildcards # noqa: F401 from ._check_assert.key_rules import ( # noqa: F401 Comparator , KeyRule , check_exact , check_suppress , check_type , gen_check_date_proximity , gen_check_date_range , ) __version__ = '1.3.0' __pkg_name__ = 'pytest_cache_assert' # ====== Above is the recommended code from calcipy_template and may be updated on new releases ======","title":"pytest_cache_assert"},{"location":"modules/pytest_cache_assert/#sub-modules","text":"pytest_cache_assert.main pytest_cache_assert.plugin","title":"Sub-modules"},{"location":"modules/pytest_cache_assert/_code_diagrams/","text":"Code Diagrams \u2693\ufe0e Auto-generated with pylint-pyreverse Packages \u2693\ufe0e Full Size Classes \u2693\ufe0e Full Size","title":"Code Diagrams"},{"location":"modules/pytest_cache_assert/_code_diagrams/#code-diagrams","text":"Auto-generated with pylint-pyreverse","title":"Code Diagrams"},{"location":"modules/pytest_cache_assert/_code_diagrams/#packages","text":"Full Size","title":"Packages"},{"location":"modules/pytest_cache_assert/_code_diagrams/#classes","text":"Full Size","title":"Classes"},{"location":"modules/pytest_cache_assert/main/","text":"pytest_cache_assert.main \u2693\ufe0e Assertion checks for unit tests. FYI: Should not require any pytest functionality View Source \"\"\"Assertion checks for unit tests. FYI: Should not require any pytest functionality \"\"\" from pathlib import Path from beartype import beartype from beartype.typing import Any , Callable , Dict , List , Optional , Union from ._check_assert import differ , error_message from ._check_assert.caching import init_cache , load_cached_data , write_cache_data from ._check_assert.constants import TEST_DATA_TYPE from ._check_assert.error_message import RichAssertionError from ._check_assert.key_rules import KeyRule _WRAP_KEY = '--wrapped--' \"\"\"Special key to convert lists to dictionaries for dictdiffer.\"\"\" @beartype def _wrap_data ( _data : Any ) -> TEST_DATA_TYPE : \"\"\"Wrap data for comparison as dictionaries. Args: _data: list or dictionary data to potentially wrap Returns: TEST_DATA_TYPE: wrapped data that is safe for comparison \"\"\" return { _WRAP_KEY : _data } if isinstance ( _data , list ) else _data ''' # FYI: Not needed because the data is already unwrapped in locals of assert_against_cache @beartype def _unwrap_data(_data: TEST_DATA_TYPE) -> Any: \"\"\"Wrap data for comparison as dictionaries. Args: _data: safe data to potentially unwrap Returns: Any: unwrapped list or dictionary data \"\"\" return _data.get(_WRAP_KEY, _data) ''' def _safe_types ( * , test_data : Any , cached_data : Any , key_rules : List [ KeyRule ], ) -> Dict [ str , Union [ TEST_DATA_TYPE , List [ KeyRule ]]]: \"\"\"Convert data and key_rules to safe data types for diffing. Args: test_data: data to compare cached_data: data to compare key_rules: list of key rules to apply Returns: Dict[str, Union[TEST_DATA_TYPE, List[KeyRule]]]: safe keyword args for diff_with_rules \"\"\" wrapped_key_rules = [] for key_rule in key_rules : if isinstance ( cached_data , list ): key_rule . pattern = [ _WRAP_KEY ] + key_rule . pattern wrapped_key_rules . append ( key_rule ) return { 'old_dict' : _wrap_data ( cached_data ), 'new_dict' : _wrap_data ( test_data ), 'key_rules' : wrapped_key_rules , } @beartype def assert_against_dict ( old_dict : dict , new_dict : dict , key_rules : Optional [ List [ KeyRule ]] = None ) -> None : \"\"\"Utilize custom DictDiffer logic to compare in-memory dictionaries. Args: old_dict: old dictionary (typically cached one) new_dict: new dictionary (typically test data) key_rules: dictionary of KeyRules to apply when selectively ignoring differences Raises: RichAssertionError: if any assertion fails \"\"\" safe_tuple = _safe_types ( cached_data = old_dict , test_data = new_dict , key_rules = key_rules or []) diff_results = differ . diff_with_rules ( ** safe_tuple ) if diff_results : kwargs = { 'new_dict' : new_dict , 'old_dict' : old_dict , 'diff_results' : diff_results , } message = f \"\"\"For test data: { new_dict } Found differences with: { old_dict } Differences: { diff_results } \"\"\" raise RichAssertionError ( message , error_info = kwargs ) @beartype def assert_against_cache ( test_data : Any , path_cache_dir : Path , cache_name : str , key_rules : Optional [ List [ KeyRule ]] = None , validator : Optional [ Callable [[ TEST_DATA_TYPE ], None ]] = None , metadata : Optional [ dict ] = None , ) -> None : \"\"\"Core logic for pytest_cache_assert to handle caching and assertion-checking. Args: test_data: dictionary or list to test (could be from cache) path_cache_dir: location of the cache directory cache_name: relative string path from the test_dir to the JSON cache file key_rules: dictionary of KeyRules to apply when selectively ignoring differences validator: Custom validation function to be run against the test data before any modification metadata: metadata dictionary to store in the cache file Raises: RichAssertionError: if any assertion fails \"\"\" validator = validator or ( lambda _res : None ) validator ( test_data ) path_cache_file = path_cache_dir / cache_name if not path_cache_dir . is_dir (): init_cache ( path_cache_dir ) write_cache_data ( path_cache_file , metadata or {}, test_data ) cached_data = load_cached_data ( path_cache_file ) safe_tuple = _safe_types ( cached_data = cached_data , test_data = test_data , key_rules = key_rules or []) diff_results = differ . diff_with_rules ( ** safe_tuple ) if diff_results : kwargs = { 'test_data' : test_data , 'cached_data' : cached_data , 'path_cache_file' : path_cache_file , 'diff_results' : diff_results , } raise RichAssertionError ( error_message . create ( ** kwargs ), error_info = kwargs ) Functions \u2693\ufe0e assert_against_cache \u2693\ufe0e def assert_against_cache ( test_data : Any , path_cache_dir : pathlib . Path , cache_name : str , key_rules : Union [ List [ pytest_cache_assert . _check_assert . key_rules . KeyRule ], NoneType ] = None , validator : Union [ Callable [[ Any ], NoneType ], NoneType ] = None , metadata : Union [ dict , NoneType ] = None ) -> None Core logic for pytest_cache_assert to handle caching and assertion-checking. Parameters: Name Description test_data dictionary or list to test (could be from cache) path_cache_dir location of the cache directory cache_name relative string path from the test_dir to the JSON cache file key_rules dictionary of KeyRules to apply when selectively ignoring differences validator Custom validation function to be run against the test data before any modification metadata metadata dictionary to store in the cache file Raises: Type Description RichAssertionError if any assertion fails View Source @beartype def assert_against_cache ( test_data : Any , path_cache_dir : Path , cache_name : str , key_rules : Optional [ List [ KeyRule ]] = None , validator : Optional [ Callable [[ TEST_DATA_TYPE ], None ]] = None , metadata : Optional [ dict ] = None , ) -> None : \"\"\"Core logic for pytest_cache_assert to handle caching and assertion-checking. Args: test_data: dictionary or list to test (could be from cache) path_cache_dir: location of the cache directory cache_name: relative string path from the test_dir to the JSON cache file key_rules: dictionary of KeyRules to apply when selectively ignoring differences validator: Custom validation function to be run against the test data before any modification metadata: metadata dictionary to store in the cache file Raises: RichAssertionError: if any assertion fails \"\"\" validator = validator or ( lambda _res : None ) validator ( test_data ) path_cache_file = path_cache_dir / cache_name if not path_cache_dir . is_dir (): init_cache ( path_cache_dir ) write_cache_data ( path_cache_file , metadata or {}, test_data ) cached_data = load_cached_data ( path_cache_file ) safe_tuple = _safe_types ( cached_data = cached_data , test_data = test_data , key_rules = key_rules or []) diff_results = differ . diff_with_rules ( ** safe_tuple ) if diff_results : kwargs = { 'test_data' : test_data , 'cached_data' : cached_data , 'path_cache_file' : path_cache_file , 'diff_results' : diff_results , } raise RichAssertionError ( error_message . create ( ** kwargs ), error_info = kwargs ) assert_against_dict \u2693\ufe0e def assert_against_dict ( old_dict : dict , new_dict : dict , key_rules : Union [ List [ pytest_cache_assert . _check_assert . key_rules . KeyRule ], NoneType ] = None ) -> None Utilize custom DictDiffer logic to compare in-memory dictionaries. Parameters: Name Description old_dict old dictionary (typically cached one) new_dict new dictionary (typically test data) key_rules dictionary of KeyRules to apply when selectively ignoring differences Raises: Type Description RichAssertionError if any assertion fails View Source @beartype def assert_against_dict ( old_dict : dict , new_dict : dict , key_rules : Optional [ List [ KeyRule ]] = None ) -> None : \"\"\"Utilize custom DictDiffer logic to compare in-memory dictionaries. Args: old_dict: old dictionary (typically cached one) new_dict: new dictionary (typically test data) key_rules: dictionary of KeyRules to apply when selectively ignoring differences Raises: RichAssertionError: if any assertion fails \"\"\" safe_tuple = _safe_types ( cached_data = old_dict , test_data = new_dict , key_rules = key_rules or []) diff_results = differ . diff_with_rules ( ** safe_tuple ) if diff_results : kwargs = { 'new_dict' : new_dict , 'old_dict' : old_dict , 'diff_results' : diff_results , } message = f \"\"\"For test data: { new_dict } Found differences with: { old_dict } Differences: { diff_results } \"\"\" raise RichAssertionError ( message , error_info = kwargs )","title":"pytest_cache_assert.main"},{"location":"modules/pytest_cache_assert/main/#pytest_cache_assertmain","text":"Assertion checks for unit tests. FYI: Should not require any pytest functionality View Source \"\"\"Assertion checks for unit tests. FYI: Should not require any pytest functionality \"\"\" from pathlib import Path from beartype import beartype from beartype.typing import Any , Callable , Dict , List , Optional , Union from ._check_assert import differ , error_message from ._check_assert.caching import init_cache , load_cached_data , write_cache_data from ._check_assert.constants import TEST_DATA_TYPE from ._check_assert.error_message import RichAssertionError from ._check_assert.key_rules import KeyRule _WRAP_KEY = '--wrapped--' \"\"\"Special key to convert lists to dictionaries for dictdiffer.\"\"\" @beartype def _wrap_data ( _data : Any ) -> TEST_DATA_TYPE : \"\"\"Wrap data for comparison as dictionaries. Args: _data: list or dictionary data to potentially wrap Returns: TEST_DATA_TYPE: wrapped data that is safe for comparison \"\"\" return { _WRAP_KEY : _data } if isinstance ( _data , list ) else _data ''' # FYI: Not needed because the data is already unwrapped in locals of assert_against_cache @beartype def _unwrap_data(_data: TEST_DATA_TYPE) -> Any: \"\"\"Wrap data for comparison as dictionaries. Args: _data: safe data to potentially unwrap Returns: Any: unwrapped list or dictionary data \"\"\" return _data.get(_WRAP_KEY, _data) ''' def _safe_types ( * , test_data : Any , cached_data : Any , key_rules : List [ KeyRule ], ) -> Dict [ str , Union [ TEST_DATA_TYPE , List [ KeyRule ]]]: \"\"\"Convert data and key_rules to safe data types for diffing. Args: test_data: data to compare cached_data: data to compare key_rules: list of key rules to apply Returns: Dict[str, Union[TEST_DATA_TYPE, List[KeyRule]]]: safe keyword args for diff_with_rules \"\"\" wrapped_key_rules = [] for key_rule in key_rules : if isinstance ( cached_data , list ): key_rule . pattern = [ _WRAP_KEY ] + key_rule . pattern wrapped_key_rules . append ( key_rule ) return { 'old_dict' : _wrap_data ( cached_data ), 'new_dict' : _wrap_data ( test_data ), 'key_rules' : wrapped_key_rules , } @beartype def assert_against_dict ( old_dict : dict , new_dict : dict , key_rules : Optional [ List [ KeyRule ]] = None ) -> None : \"\"\"Utilize custom DictDiffer logic to compare in-memory dictionaries. Args: old_dict: old dictionary (typically cached one) new_dict: new dictionary (typically test data) key_rules: dictionary of KeyRules to apply when selectively ignoring differences Raises: RichAssertionError: if any assertion fails \"\"\" safe_tuple = _safe_types ( cached_data = old_dict , test_data = new_dict , key_rules = key_rules or []) diff_results = differ . diff_with_rules ( ** safe_tuple ) if diff_results : kwargs = { 'new_dict' : new_dict , 'old_dict' : old_dict , 'diff_results' : diff_results , } message = f \"\"\"For test data: { new_dict } Found differences with: { old_dict } Differences: { diff_results } \"\"\" raise RichAssertionError ( message , error_info = kwargs ) @beartype def assert_against_cache ( test_data : Any , path_cache_dir : Path , cache_name : str , key_rules : Optional [ List [ KeyRule ]] = None , validator : Optional [ Callable [[ TEST_DATA_TYPE ], None ]] = None , metadata : Optional [ dict ] = None , ) -> None : \"\"\"Core logic for pytest_cache_assert to handle caching and assertion-checking. Args: test_data: dictionary or list to test (could be from cache) path_cache_dir: location of the cache directory cache_name: relative string path from the test_dir to the JSON cache file key_rules: dictionary of KeyRules to apply when selectively ignoring differences validator: Custom validation function to be run against the test data before any modification metadata: metadata dictionary to store in the cache file Raises: RichAssertionError: if any assertion fails \"\"\" validator = validator or ( lambda _res : None ) validator ( test_data ) path_cache_file = path_cache_dir / cache_name if not path_cache_dir . is_dir (): init_cache ( path_cache_dir ) write_cache_data ( path_cache_file , metadata or {}, test_data ) cached_data = load_cached_data ( path_cache_file ) safe_tuple = _safe_types ( cached_data = cached_data , test_data = test_data , key_rules = key_rules or []) diff_results = differ . diff_with_rules ( ** safe_tuple ) if diff_results : kwargs = { 'test_data' : test_data , 'cached_data' : cached_data , 'path_cache_file' : path_cache_file , 'diff_results' : diff_results , } raise RichAssertionError ( error_message . create ( ** kwargs ), error_info = kwargs )","title":"pytest_cache_assert.main"},{"location":"modules/pytest_cache_assert/main/#functions","text":"","title":"Functions"},{"location":"modules/pytest_cache_assert/main/#assert_against_cache","text":"def assert_against_cache ( test_data : Any , path_cache_dir : pathlib . Path , cache_name : str , key_rules : Union [ List [ pytest_cache_assert . _check_assert . key_rules . KeyRule ], NoneType ] = None , validator : Union [ Callable [[ Any ], NoneType ], NoneType ] = None , metadata : Union [ dict , NoneType ] = None ) -> None Core logic for pytest_cache_assert to handle caching and assertion-checking. Parameters: Name Description test_data dictionary or list to test (could be from cache) path_cache_dir location of the cache directory cache_name relative string path from the test_dir to the JSON cache file key_rules dictionary of KeyRules to apply when selectively ignoring differences validator Custom validation function to be run against the test data before any modification metadata metadata dictionary to store in the cache file Raises: Type Description RichAssertionError if any assertion fails View Source @beartype def assert_against_cache ( test_data : Any , path_cache_dir : Path , cache_name : str , key_rules : Optional [ List [ KeyRule ]] = None , validator : Optional [ Callable [[ TEST_DATA_TYPE ], None ]] = None , metadata : Optional [ dict ] = None , ) -> None : \"\"\"Core logic for pytest_cache_assert to handle caching and assertion-checking. Args: test_data: dictionary or list to test (could be from cache) path_cache_dir: location of the cache directory cache_name: relative string path from the test_dir to the JSON cache file key_rules: dictionary of KeyRules to apply when selectively ignoring differences validator: Custom validation function to be run against the test data before any modification metadata: metadata dictionary to store in the cache file Raises: RichAssertionError: if any assertion fails \"\"\" validator = validator or ( lambda _res : None ) validator ( test_data ) path_cache_file = path_cache_dir / cache_name if not path_cache_dir . is_dir (): init_cache ( path_cache_dir ) write_cache_data ( path_cache_file , metadata or {}, test_data ) cached_data = load_cached_data ( path_cache_file ) safe_tuple = _safe_types ( cached_data = cached_data , test_data = test_data , key_rules = key_rules or []) diff_results = differ . diff_with_rules ( ** safe_tuple ) if diff_results : kwargs = { 'test_data' : test_data , 'cached_data' : cached_data , 'path_cache_file' : path_cache_file , 'diff_results' : diff_results , } raise RichAssertionError ( error_message . create ( ** kwargs ), error_info = kwargs )","title":"assert_against_cache"},{"location":"modules/pytest_cache_assert/main/#assert_against_dict","text":"def assert_against_dict ( old_dict : dict , new_dict : dict , key_rules : Union [ List [ pytest_cache_assert . _check_assert . key_rules . KeyRule ], NoneType ] = None ) -> None Utilize custom DictDiffer logic to compare in-memory dictionaries. Parameters: Name Description old_dict old dictionary (typically cached one) new_dict new dictionary (typically test data) key_rules dictionary of KeyRules to apply when selectively ignoring differences Raises: Type Description RichAssertionError if any assertion fails View Source @beartype def assert_against_dict ( old_dict : dict , new_dict : dict , key_rules : Optional [ List [ KeyRule ]] = None ) -> None : \"\"\"Utilize custom DictDiffer logic to compare in-memory dictionaries. Args: old_dict: old dictionary (typically cached one) new_dict: new dictionary (typically test data) key_rules: dictionary of KeyRules to apply when selectively ignoring differences Raises: RichAssertionError: if any assertion fails \"\"\" safe_tuple = _safe_types ( cached_data = old_dict , test_data = new_dict , key_rules = key_rules or []) diff_results = differ . diff_with_rules ( ** safe_tuple ) if diff_results : kwargs = { 'new_dict' : new_dict , 'old_dict' : old_dict , 'diff_results' : diff_results , } message = f \"\"\"For test data: { new_dict } Found differences with: { old_dict } Differences: { diff_results } \"\"\" raise RichAssertionError ( message , error_info = kwargs )","title":"assert_against_dict"},{"location":"modules/pytest_cache_assert/plugin/","text":"pytest_cache_assert.plugin \u2693\ufe0e Pytest Plugin. View Source \"\"\"Pytest Plugin.\"\"\" import inspect from functools import partial from pathlib import Path import pytest from _pytest.fixtures import FixtureRequest from attrs import field , frozen from attrs_strict import type_validator from beartype import beartype from beartype.typing import Any , Callable , List , Optional , Tuple from . import main from ._check_assert.config import CacheAssertContainerKeys , cache_assert_container from ._check_assert.constants import DEF_CACHE_DIR_NAME from ._check_assert.serializer import recursive_serialize @frozen ( kw_only = True ) class AssertConfig : \"\"\"User configuration data structure.\"\"\" cache_dir_rel_path : str = field ( default = DEF_CACHE_DIR_NAME , validator = type_validator ()) \"\"\"String relative directory to `tests/`. Default resolves to `tests/assert-cache/`.\"\"\" extra_ser_rules : List [ Tuple [ Any , Callable [[ Any ], Any ]]] = field ( factory = list , validator = type_validator ()) \"\"\"Additional serialization rules. Example: `[(Enum, lambda _e: _e.name), (doit.tools.Interactive, str)]`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Register relevant configuration options.\"\"\" cache_assert_container . register ( CacheAssertContainerKeys . SER_RULES , instance = self . extra_ser_rules ) @pytest . fixture () def cache_assert_config () -> AssertConfig : \"\"\"Configure pytest_cache_assert using `AssertConfig`.\"\"\" return AssertConfig () @beartype def _calculate_metadata ( request : FixtureRequest , rel_test_file : Path ) -> dict : \"\"\"Calculate metadata. Args: request: pytest fixture used to identify the test directory rel_test_file: relative path to the test file Returns: dict: new_metadata \"\"\" test_name = ( f ' { request . cls . __name__ } /' if request . cls else '' ) + request . node . originalname test_params = [ * inspect . signature ( request . node . function ) . parameters . keys ()] raw_args = { key : value for key , value in request . node . funcargs . items () if key in test_params } func_args = { key : recursive_serialize ( value ) for key , value in raw_args . items ()} return { 'test_file' : rel_test_file . as_posix (), 'test_name' : test_name , 'func_args' : func_args } @pytest . fixture () @beartype def assert_against_cache ( request : FixtureRequest , cache_assert_config : Optional [ AssertConfig ], ) -> Callable [[ Any ], None ]: \"\"\"Return main.assert_against_cache with pytest-specific arguments already specified. Args: request: pytest fixture used to identify the test directory cache_assert_config: pytest fixture that returns AssertConfig for user configuration Returns: Callable[[Any], None]: `main.assert_against_cache()` with test_dir already specified Raises: RuntimeError: if the test directory cannot be determined \"\"\" cache_assert_config = cache_assert_config or AssertConfig () test_dir = None for sub_dir in [ 'tests' , 'test' ]: test_dir = request . config . rootpath / sub_dir if test_dir . is_dir (): break else : raise RuntimeError ( f 'Could not locate a \"tests/\" directory in { test_dir } ' ) # Read user settings path_cache_dir = test_dir / cache_assert_config . cache_dir_rel_path # Calculate keyword arguments rel_test_file = Path ( request . node . fspath ) . relative_to ( test_dir ) cache_name = ( rel_test_file . parent / f ' { request . node . name } .json' ) . as_posix () # noqa: ECE001 metadata = _calculate_metadata ( request , rel_test_file ) # FYI: The partial function keyword arguments can be overridden when called return partial ( main . assert_against_cache , path_cache_dir = path_cache_dir , cache_name = cache_name , metadata = metadata ) Variables \u2693\ufe0e DEF_CACHE_DIR_NAME frozen Functions \u2693\ufe0e assert_against_cache \u2693\ufe0e def assert_against_cache ( request : _pytest . fixtures . FixtureRequest , cache_assert_config : Union [ pytest_cache_assert . plugin . AssertConfig , NoneType ] ) -> Callable [[ Any ], NoneType ] Return main.assert_against_cache with pytest-specific arguments already specified. Parameters: Name Description request pytest fixture used to identify the test directory cache_assert_config pytest fixture that returns AssertConfig for user configuration Returns: Type Description Callable[[Any], None] main.assert_against_cache() with test_dir already specified Raises: Type Description RuntimeError if the test directory cannot be determined View Source @pytest . fixture () @beartype def assert_against_cache ( request : FixtureRequest , cache_assert_config : Optional [ AssertConfig ], ) -> Callable [[ Any ], None ]: \"\"\"Return main.assert_against_cache with pytest-specific arguments already specified. Args: request: pytest fixture used to identify the test directory cache_assert_config: pytest fixture that returns AssertConfig for user configuration Returns: Callable[[Any], None]: `main.assert_against_cache()` with test_dir already specified Raises: RuntimeError: if the test directory cannot be determined \"\"\" cache_assert_config = cache_assert_config or AssertConfig () test_dir = None for sub_dir in [ 'tests' , 'test' ]: test_dir = request . config . rootpath / sub_dir if test_dir . is_dir (): break else : raise RuntimeError ( f 'Could not locate a \"tests/\" directory in { test_dir } ' ) # Read user settings path_cache_dir = test_dir / cache_assert_config . cache_dir_rel_path # Calculate keyword arguments rel_test_file = Path ( request . node . fspath ) . relative_to ( test_dir ) cache_name = ( rel_test_file . parent / f ' { request . node . name } .json' ) . as_posix () # noqa: ECE001 metadata = _calculate_metadata ( request , rel_test_file ) # FYI: The partial function keyword arguments can be overridden when called return partial ( main . assert_against_cache , path_cache_dir = path_cache_dir , cache_name = cache_name , metadata = metadata ) cache_assert_config \u2693\ufe0e def cache_assert_config () -> pytest_cache_assert . plugin . AssertConfig Configure pytest_cache_assert using AssertConfig . View Source @pytest . fixture () def cache_assert_config () -> AssertConfig : \"\"\"Configure pytest_cache_assert using `AssertConfig`.\"\"\" return AssertConfig () Classes \u2693\ufe0e AssertConfig \u2693\ufe0e class AssertConfig ( * , cache_dir_rel_path : str = 'assert-cache' , extra_ser_rules : List [ Tuple [ Any , Callable [[ Any ], Any ]]] = NOTHING ) View Source class AssertConfig : \"\"\"User configuration data structure.\"\"\" cache_dir_rel_path : str = field ( default = DEF_CACHE_DIR_NAME , validator = type_validator ()) \"\"\"String relative directory to `tests/`. Default resolves to `tests/assert-cache/`.\"\"\" extra_ser_rules : List [ Tuple [ Any , Callable [[ Any ], Any ]]] = field ( factory = list , validator = type_validator ()) \"\"\"Additional serialization rules. Example: `[(Enum, lambda _e: _e.name), (doit.tools.Interactive, str)]`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Register relevant configuration options.\"\"\" cache_assert_container . register ( CacheAssertContainerKeys . SER_RULES , instance = self . extra_ser_rules ) Instance variables \u2693\ufe0e cache_dir_rel_path extra_ser_rules","title":"pytest_cache_assert.plugin"},{"location":"modules/pytest_cache_assert/plugin/#pytest_cache_assertplugin","text":"Pytest Plugin. View Source \"\"\"Pytest Plugin.\"\"\" import inspect from functools import partial from pathlib import Path import pytest from _pytest.fixtures import FixtureRequest from attrs import field , frozen from attrs_strict import type_validator from beartype import beartype from beartype.typing import Any , Callable , List , Optional , Tuple from . import main from ._check_assert.config import CacheAssertContainerKeys , cache_assert_container from ._check_assert.constants import DEF_CACHE_DIR_NAME from ._check_assert.serializer import recursive_serialize @frozen ( kw_only = True ) class AssertConfig : \"\"\"User configuration data structure.\"\"\" cache_dir_rel_path : str = field ( default = DEF_CACHE_DIR_NAME , validator = type_validator ()) \"\"\"String relative directory to `tests/`. Default resolves to `tests/assert-cache/`.\"\"\" extra_ser_rules : List [ Tuple [ Any , Callable [[ Any ], Any ]]] = field ( factory = list , validator = type_validator ()) \"\"\"Additional serialization rules. Example: `[(Enum, lambda _e: _e.name), (doit.tools.Interactive, str)]`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Register relevant configuration options.\"\"\" cache_assert_container . register ( CacheAssertContainerKeys . SER_RULES , instance = self . extra_ser_rules ) @pytest . fixture () def cache_assert_config () -> AssertConfig : \"\"\"Configure pytest_cache_assert using `AssertConfig`.\"\"\" return AssertConfig () @beartype def _calculate_metadata ( request : FixtureRequest , rel_test_file : Path ) -> dict : \"\"\"Calculate metadata. Args: request: pytest fixture used to identify the test directory rel_test_file: relative path to the test file Returns: dict: new_metadata \"\"\" test_name = ( f ' { request . cls . __name__ } /' if request . cls else '' ) + request . node . originalname test_params = [ * inspect . signature ( request . node . function ) . parameters . keys ()] raw_args = { key : value for key , value in request . node . funcargs . items () if key in test_params } func_args = { key : recursive_serialize ( value ) for key , value in raw_args . items ()} return { 'test_file' : rel_test_file . as_posix (), 'test_name' : test_name , 'func_args' : func_args } @pytest . fixture () @beartype def assert_against_cache ( request : FixtureRequest , cache_assert_config : Optional [ AssertConfig ], ) -> Callable [[ Any ], None ]: \"\"\"Return main.assert_against_cache with pytest-specific arguments already specified. Args: request: pytest fixture used to identify the test directory cache_assert_config: pytest fixture that returns AssertConfig for user configuration Returns: Callable[[Any], None]: `main.assert_against_cache()` with test_dir already specified Raises: RuntimeError: if the test directory cannot be determined \"\"\" cache_assert_config = cache_assert_config or AssertConfig () test_dir = None for sub_dir in [ 'tests' , 'test' ]: test_dir = request . config . rootpath / sub_dir if test_dir . is_dir (): break else : raise RuntimeError ( f 'Could not locate a \"tests/\" directory in { test_dir } ' ) # Read user settings path_cache_dir = test_dir / cache_assert_config . cache_dir_rel_path # Calculate keyword arguments rel_test_file = Path ( request . node . fspath ) . relative_to ( test_dir ) cache_name = ( rel_test_file . parent / f ' { request . node . name } .json' ) . as_posix () # noqa: ECE001 metadata = _calculate_metadata ( request , rel_test_file ) # FYI: The partial function keyword arguments can be overridden when called return partial ( main . assert_against_cache , path_cache_dir = path_cache_dir , cache_name = cache_name , metadata = metadata )","title":"pytest_cache_assert.plugin"},{"location":"modules/pytest_cache_assert/plugin/#variables","text":"DEF_CACHE_DIR_NAME frozen","title":"Variables"},{"location":"modules/pytest_cache_assert/plugin/#functions","text":"","title":"Functions"},{"location":"modules/pytest_cache_assert/plugin/#assert_against_cache","text":"def assert_against_cache ( request : _pytest . fixtures . FixtureRequest , cache_assert_config : Union [ pytest_cache_assert . plugin . AssertConfig , NoneType ] ) -> Callable [[ Any ], NoneType ] Return main.assert_against_cache with pytest-specific arguments already specified. Parameters: Name Description request pytest fixture used to identify the test directory cache_assert_config pytest fixture that returns AssertConfig for user configuration Returns: Type Description Callable[[Any], None] main.assert_against_cache() with test_dir already specified Raises: Type Description RuntimeError if the test directory cannot be determined View Source @pytest . fixture () @beartype def assert_against_cache ( request : FixtureRequest , cache_assert_config : Optional [ AssertConfig ], ) -> Callable [[ Any ], None ]: \"\"\"Return main.assert_against_cache with pytest-specific arguments already specified. Args: request: pytest fixture used to identify the test directory cache_assert_config: pytest fixture that returns AssertConfig for user configuration Returns: Callable[[Any], None]: `main.assert_against_cache()` with test_dir already specified Raises: RuntimeError: if the test directory cannot be determined \"\"\" cache_assert_config = cache_assert_config or AssertConfig () test_dir = None for sub_dir in [ 'tests' , 'test' ]: test_dir = request . config . rootpath / sub_dir if test_dir . is_dir (): break else : raise RuntimeError ( f 'Could not locate a \"tests/\" directory in { test_dir } ' ) # Read user settings path_cache_dir = test_dir / cache_assert_config . cache_dir_rel_path # Calculate keyword arguments rel_test_file = Path ( request . node . fspath ) . relative_to ( test_dir ) cache_name = ( rel_test_file . parent / f ' { request . node . name } .json' ) . as_posix () # noqa: ECE001 metadata = _calculate_metadata ( request , rel_test_file ) # FYI: The partial function keyword arguments can be overridden when called return partial ( main . assert_against_cache , path_cache_dir = path_cache_dir , cache_name = cache_name , metadata = metadata )","title":"assert_against_cache"},{"location":"modules/pytest_cache_assert/plugin/#cache_assert_config","text":"def cache_assert_config () -> pytest_cache_assert . plugin . AssertConfig Configure pytest_cache_assert using AssertConfig . View Source @pytest . fixture () def cache_assert_config () -> AssertConfig : \"\"\"Configure pytest_cache_assert using `AssertConfig`.\"\"\" return AssertConfig ()","title":"cache_assert_config"},{"location":"modules/pytest_cache_assert/plugin/#classes","text":"","title":"Classes"},{"location":"modules/pytest_cache_assert/plugin/#assertconfig","text":"class AssertConfig ( * , cache_dir_rel_path : str = 'assert-cache' , extra_ser_rules : List [ Tuple [ Any , Callable [[ Any ], Any ]]] = NOTHING ) View Source class AssertConfig : \"\"\"User configuration data structure.\"\"\" cache_dir_rel_path : str = field ( default = DEF_CACHE_DIR_NAME , validator = type_validator ()) \"\"\"String relative directory to `tests/`. Default resolves to `tests/assert-cache/`.\"\"\" extra_ser_rules : List [ Tuple [ Any , Callable [[ Any ], Any ]]] = field ( factory = list , validator = type_validator ()) \"\"\"Additional serialization rules. Example: `[(Enum, lambda _e: _e.name), (doit.tools.Interactive, str)]`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Register relevant configuration options.\"\"\" cache_assert_container . register ( CacheAssertContainerKeys . SER_RULES , instance = self . extra_ser_rules )","title":"AssertConfig"},{"location":"modules/pytest_cache_assert/plugin/#instance-variables","text":"cache_dir_rel_path extra_ser_rules","title":"Instance variables"}]}